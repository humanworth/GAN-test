{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQSjJwDxnmiAymFK3LnWnA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/humanworth/GAN-test/blob/main/GAN-test\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1- Import dependencies and data**"
      ],
      "metadata": {
        "id": "2zw1veulgdGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow \n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "B5rOCtyWi2ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib tensorflow-datasets ipywidgets"
      ],
      "metadata": {
        "id": "8KGRNPoikcHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y04m-jvKRDsJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu,True)\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "from matplotlib import pyplot as plt\n",
        "ds = tfds.load(\"fashion_mnist\", split=\"train\")"
      ],
      "metadata": {
        "id": "IGNZXStGV4s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2- visualize data and build dataset**"
      ],
      "metadata": {
        "id": "SH--YUY8gro8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "dataset_iterator = ds.as_numpy_iterator()\n",
        "img1 = np.squeeze(dataset_iterator.next()[\"image\"])\n",
        "np.shape(dataset_iterator.next()[\"image\"])\n",
        "fix, ax = plt.subplots(ncols=4,figsize=(20,20))\n",
        "for idx in range(4):\n",
        "  sample = dataset_iterator.next()\n",
        "  ax[idx].imshow(np.squeeze(sample['image']))\n",
        "  ax[idx].title.set_text(sample['label'])"
      ],
      "metadata": {
        "id": "13Q1Hu-7YpjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_dataset(data):\n",
        "  image = data['image']\n",
        "  return image/255"
      ],
      "metadata": {
        "id": "CQwWA0SZmRTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tfds.load(\"fashion_mnist\", split=\"train\")\n",
        "scaled_images = scale_dataset(ds)\n",
        "ds = ds.map(scaled_images)\n",
        "ds = ds.cache()\n",
        "ds = ds.shuffle(60000)\n",
        "ds = ds.batch(128)\n",
        "ds = ds.prefetch(64)\n"
      ],
      "metadata": {
        "id": "naeZ6In6mrnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3- build neural network**"
      ],
      "metadata": {
        "id": "_d7MbBofg42p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, UpSampling2D "
      ],
      "metadata": {
        "id": "saTqH1RCqAHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1- Import modeling components**"
      ],
      "metadata": {
        "id": "damq0JtIhBxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2- build generator**"
      ],
      "metadata": {
        "id": "4fL8xZQKhNhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(7*7*128,input_dim=128))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Reshape((7,7,128)))\n",
        "\n",
        "  model.add(UpSampling2D())\n",
        "  model.add(Conv2D(128,5,padding='same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  return model"
      ],
      "metadata": {
        "id": "5vaAvtsFtrd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model=build_generator()\n",
        "test_model.summary()"
      ],
      "metadata": {
        "id": "QEE82Cmhu9Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3- build discriminator**"
      ],
      "metadata": {
        "id": "lLzgKSNNhPsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. construct training loop**"
      ],
      "metadata": {
        "id": "SwC9yuHohnYU"
      }
    }
  ]
}